[ConnectionSettings]
#REDIS_URL= 10.1.0.120
REDIS_URL=localhost
REDIS_PORT=6379
HASH = sensor_data
CITY_PREFIX =  dublin

[SensorsAvailable]
sensor1 = Noisetube
sensor2 = DublinCityCouncilAirPollution
sensor3 = Temperature
sensor4 = Humidity
sensor5 = Dewpoint
sensor6 = Pressure
sensor7 = Rainfall
sensor8 = CO2
sensor9 = NH2
sensor10 = Pollutant
sensor11 = Accelerometer

[Noisetube]
# The text that will appear in the web app page indicating the weighing options. The user can choose between fastest, shortest (which are supported by GH but only fastest is
#implemented in the web app). Given available sensor data, the user can also choose to maximize, minimize sensor data;i.e LeastNoisy for the Noisetube sensor.
text = Least_Noisy 

# Type of sensor readings; e.g. noise, air...etc. To be used in naming the hashes, such as city_type_set. That's important to be able to retrieve the relevant readings  of the
#relevant city from Graphhooper during routing calculation
type = noise

# Name of the function inside the 'webservices' that can call the required webservice
webservice = webservices.call_nt_webservice


# URL where the webservice that retrieves data from sensors is located
url = http://www.noisetube.net/api/search.json?key=

# API key of the user calling the webservice
api_key = 12da65cd7932fb3a0543009fb78ba08711bed72b

# ID of the city we want to retrieve data about. Currently, this is obtained by 
# sending a polite email to the NoiseTube admin
city_id = 136

# Name of the parser inside module 'sensorparsers' that can parse data returned 
# by the webservice_url above
parser = sensorparsers.create_noise_sensor_hash

# Name of the aggregator inside module 'aggregators' that can aggregate 
# data for this particular sensor
aggregator = aggregators.exponential_weighted_moving_average

# Directory where the sensor parser stores the aggregated data
dirname = sensor_readings/noise/

# Specifies the filepattern which much be globbed. Globbing is done in almost 
# the same manner as the unix shell. '*' and '?' will work as wildcard 
# characters. [] can be used to express character ranges as well. However, dot 
# files are not matched by default, using '*'. If we need to match dot files, 
# then we need to specify something like '.sensor*.xml' [note the explicit dot 
# in the beginning]
filepattern = latest_noisetube_readings.json

# The number of meters where the sensor's readings propagate to
propagation = 50

# The number of days that aggregation filter will take into consideration
days = 3

[DublinCityCouncilAirPollution]
# The text that will appear in the web app page indicating the weighing 
# options. The user can choose between fastest, shortest (which are supported 
# by GH but only fastest is
#implemented in the web app). Given available sensor data, the user can also choose to maximize, minimize sensor data;i.e LeastNoisy for the Noisetube sensor.
text = Least_Air_Polluted

# Type of sensor readings; e.g. noise, air...etc. To be used to in naming the hashes, such as city_type_set. That's important to be able to retrieve the relevant readings  of the
#relevant city from Graphhooper during routing calculation
type = air

# Name of the function inside the 'webservices' that can call the required webservice
webservice = webservices.call_noop_webservice


# URL where the webservice that retrieves data from sensors is located
url = http://www.noisetube.net/api/search.json?key=

# API key of the user calling the webservice
api_key = 12da65cd7932fb3a0543009fb78ba08711bed72b

# ID of the city we want to retrieve data about. Currently, this is obtained by 
# sending a polite email to the NoiseTube admin
city_id = 136

# Name of the parser inside module 'sensorparsers' that can parse data returned 
# by the webservice_url above
parser = sensorparsers.create_air_sensor_hash

# Name of the aggregator inside module 'aggregators' that can aggregate 
# data for this particular sensor
aggregator = aggregators.noop_aggregator

# Directory where the sensor parser stores the aggregated data
dirname = sensor_readings/air/

# Specifies the filepattern which much be globbed. Globbing is done in almost 
# the same manner as the unix shell. '*' and '?' will work as wildcard 
# characters. [] can be used to express character ranges as well. However, dot 
# files are not matched by default, using '*'. If we need to match dot files, 
# then we need to specify something like '.sensor*.xml' [note the explicit dot 
# in the beginning]
filepattern = *.csv

# The number of meters where the sensor's readings propagate to
propagation = 500

# The number of days that aggregation filter will take into consideration
days = 3

[Temperature]
# The text that will appear in the web app page indicating the weighing 
# options. The user can choose between fastest, shortest (which are supported 
# by GH but only fastest is
#implemented in the web app). Given available sensor data, the user can also choose to maximize, minimize sensor data;i.e LeastNoisy for the Noisetube sensor.
text = Least_Cold

# Type of sensor readings; e.g. noise, air...etc. To be used to in naming the hashes, such as city_type_set. That's important to be able to retrieve the relevant readings  of the
#relevant city from Graphhooper during routing calculation
type = temperature

# Name of the function inside the 'webservices' that can call the required webservice
webservice = webservices.call_noop_webservice

# Name of the parser inside module 'sensorparsers' that can parse data returned 
# by the webservice_url above
parser = sensorparsers.create_temperature_sensor_hash

# Name of the aggregator inside module 'aggregators' that can aggregate 
# data for this particular sensor
aggregator = aggregators.noop_aggregator

# Directory where the sensor parser stores the aggregated data
dirname = sensor_readings/temperature/

# Specifies the filepattern which much be globbed. Globbing is done in almost 
# the same manner as the unix shell. '*' and '?' will work as wildcard 
# characters. [] can be used to express character ranges as well. However, dot 
# files are not matched by default, using '*'. If we need to match dot files, 
# then we need to specify something like '.sensor*.xml' [note the explicit dot 
# in the beginning]
filepattern = *.dat

# The number of meters where the sensor's readings propagate to
propagation = 100

# The number of days that aggregation filter will take into consideration
days = 3

[Humidity]
# The text that will appear in the web app page indicating the weighing 
# options. The user can choose between fastest, shortest (which are supported 
# by GH but only fastest is
#implemented in the web app). Given available sensor data, the user can also choose to maximize, minimize sensor data;i.e LeastNoisy for the Noisetube sensor.
text = Least_Humid 

# Type of sensor readings; e.g. noise, air...etc. To be used to in naming the hashes, such as city_type_set. That's important to be able to retrieve the relevant readings  of the
#relevant city from Graphhooper during routing calculation
type = humidity

# Name of the function inside the 'webservices' that can call the required webservice
webservice = webservices.call_noop_webservice

# Name of the parser inside module 'sensorparsers' that can parse data returned 
# by the webservice_url above
parser = sensorparsers.create_humidity_sensor_hash

# Name of the aggregator inside module 'aggregators' that can aggregate 
# data for this particular sensor
aggregator = aggregators.noop_aggregator

# Directory where the sensor parser stores the aggregated data
dirname = sensor_readings/humidity/

# Specifies the filepattern which much be globbed. Globbing is done in almost 
# the same manner as the unix shell. '*' and '?' will work as wildcard 
# characters. [] can be used to express character ranges as well. However, dot 
# files are not matched by default, using '*'. If we need to match dot files, 
# then we need to specify something like '.sensor*.xml' [note the explicit dot 
# in the beginning]
filepattern = *.dat

# The number of meters where the sensor's readings propagate to
propagation = 50

# The number of days that aggregation filter will take into consideration
days = 3

[Dewpoint]
# The text that will appear in the web app page indicating the weighing 
# options. The user can choose between fastest, shortest (which are supported 
# by GH but only fastest is
#implemented in the web app). Given available sensor data, the user can also choose to maximize, minimize sensor data;i.e LeastNoisy for the Noisetube sensor.
text = Highest_Dewpoint 

# Type of sensor readings; e.g. noise, air...etc. To be used to in naming the hashes, such as city_type_set. That's important to be able to retrieve the relevant readings  of the
#relevant city from Graphhooper during routing calculation
type = dewpoint

# Name of the function inside the 'webservices' that can call the required webservice
webservice = webservices.call_noop_webservice

# Name of the parser inside module 'sensorparsers' that can parse data returned 
# by the webservice_url above
parser = sensorparsers.create_dewpoint_sensor_hash

# Name of the aggregator inside module 'aggregators' that can aggregate 
# data for this particular sensor
aggregator = aggregators.noop_aggregator

# Directory where the sensor parser stores the aggregated data
dirname = sensor_readings/dewpoint/

# Specifies the filepattern which much be globbed. Globbing is done in almost 
# the same manner as the unix shell. '*' and '?' will work as wildcard 
# characters. [] can be used to express character ranges as well. However, dot 
# files are not matched by default, using '*'. If we need to match dot files, 
# then we need to specify something like '.sensor*.xml' [note the explicit dot 
# in the beginning]
filepattern = *.dat

# The number of meters where the sensor's readings propagate to
propagation = 50

# The number of days that aggregation filter will take into consideration
days = 3

[Pressure]
# The text that will appear in the web app page indicating the weighing 
# options. The user can choose between fastest, shortest (which are supported 
# by GH but only fastest is
#implemented in the web app). Given available sensor data, the user can also choose to maximize, minimize sensor data;i.e LeastNoisy for the Noisetube sensor.
text = Least_Pressure

# Type of sensor readings; e.g. noise, air...etc. To be used to in naming the hashes, such as city_type_set. That's important to be able to retrieve the relevant readings  of the
#relevant city from Graphhooper during routing calculation
type = pressure

# Name of the function inside the 'webservices' that can call the required webservice
webservice = webservices.call_noop_webservice

# Name of the parser inside module 'sensorparsers' that can parse data returned 
# by the webservice_url above
parser = sensorparsers.create_pressure_sensor_hash

# Name of the aggregator inside module 'aggregators' that can aggregate 
# data for this particular sensor
aggregator = aggregators.noop_aggregator

# Directory where the sensor parser stores the aggregated data
dirname = sensor_readings/pressure/

# Specifies the filepattern which much be globbed. Globbing is done in almost 
# the same manner as the unix shell. '*' and '?' will work as wildcard 
# characters. [] can be used to express character ranges as well. However, dot 
# files are not matched by default, using '*'. If we need to match dot files, 
# then we need to specify something like '.sensor*.xml' [note the explicit dot 
# in the beginning]
filepattern = *.dat

# The number of meters where the sensor's readings propagate to
propagation = 50

# The number of days that aggregation filter will take into consideration
days = 3

[Rainfall]
# The text that will appear in the web app page indicating the weighing 
# options. The user can choose between fastest, shortest (which are supported 
# by GH but only fastest is
#implemented in the web app). Given available sensor data, the user can also choose to maximize, minimize sensor data;i.e LeastNoisy for the Noisetube sensor.
text = Least_Rainy

# Type of sensor readings; e.g. noise, air...etc. To be used to in naming the hashes, such as city_type_set. That's important to be able to retrieve the relevant readings  of the
#relevant city from Graphhooper during routing calculation
type = rain

# Name of the function inside the 'webservices' that can call the required webservice
webservice = webservices.call_noop_webservice

# Name of the parser inside module 'sensorparsers' that can parse data returned 
# by the webservice_url above
parser = sensorparsers.create_rain_sensor_hash

# Name of the aggregator inside module 'aggregators' that can aggregate 
# data for this particular sensor
aggregator = aggregators.noop_aggregator

# Directory where the sensor parser stores the aggregated data
dirname = sensor_readings/rain/

# Specifies the filepattern which much be globbed. Globbing is done in almost 
# the same manner as the unix shell. '*' and '?' will work as wildcard 
# characters. [] can be used to express character ranges as well. However, dot 
# files are not matched by default, using '*'. If we need to match dot files, 
# then we need to specify something like '.sensor*.xml' [note the explicit dot 
# in the beginning]
filepattern = *.dat

# The number of meters where the sensor's readings propagate to
propagation = 50

# The number of days that aggregation filter will take into consideration
days = 3

[CO2]
# The text that will appear in the web app page indicating the weighing 
# options. The user can choose between fastest, shortest (which are supported 
# by GH but only fastest is
#implemented in the web app). Given available sensor data, the user can also choose to maximize, minimize sensor data;i.e LeastNoisy for the Noisetube sensor.
text = Least_CO2

# Type of sensor readings; e.g. noise, air...etc. To be used to in naming the hashes, such as city_type_set. That's important to be able to retrieve the relevant readings  of the
#relevant city from Graphhooper during routing calculation
type = co2

# Name of the function inside the 'webservices' that can call the required webservice
webservice = webservices.call_noop_webservice

# Name of the parser inside module 'sensorparsers' that can parse data returned 
# by the webservice_url above
parser = sensorparsers.create_co2_sensor_hash

# Name of the aggregator inside module 'aggregators' that can aggregate 
# data for this particular sensor
aggregator = aggregators.noop_aggregator

# Directory where the sensor parser stores the aggregated data
dirname = sensor_readings/co2/

# Specifies the filepattern which much be globbed. Globbing is done in almost 
# the same manner as the unix shell. '*' and '?' will work as wildcard 
# characters. [] can be used to express character ranges as well. However, dot 
# files are not matched by default, using '*'. If we need to match dot files, 
# then we need to specify something like '.sensor*.xml' [note the explicit dot 
# in the beginning]
filepattern = *.dat

# The number of meters where the sensor's readings propagate to
propagation = 150

# The number of days that aggregation filter will take into consideration
days = 3

[NH2]
# The text that will appear in the web app page indicating the weighing 
# options. The user can choose between fastest, shortest (which are supported 
# by GH but only fastest is
#implemented in the web app). Given available sensor data, the user can also choose to maximize, minimize sensor data;i.e LeastNoisy for the Noisetube sensor.
text = Least_NH2

# Type of sensor readings; e.g. noise, air...etc. To be used to in naming the hashes, such as city_type_set. That's important to be able to retrieve the relevant readings  of the
#relevant city from Graphhooper during routing calculation
type = nh2

# Name of the function inside the 'webservices' that can call the required webservice
webservice = webservices.call_noop_webservice

# Name of the parser inside module 'sensorparsers' that can parse data returned 
# by the webservice_url above
parser = sensorparsers.create_nh2_sensor_hash

# Name of the aggregator inside module 'aggregators' that can aggregate 
# data for this particular sensor
aggregator = aggregators.noop_aggregator

# Directory where the sensor parser stores the aggregated data
dirname = sensor_readings/nh2/

# Specifies the filepattern which much be globbed. Globbing is done in almost 
# the same manner as the unix shell. '*' and '?' will work as wildcard 
# characters. [] can be used to express character ranges as well. However, dot 
# files are not matched by default, using '*'. If we need to match dot files, 
# then we need to specify something like '.sensor*.xml' [note the explicit dot 
# in the beginning]
filepattern = *.dat

# The number of meters where the sensor's readings propagate to
propagation = 50

# The number of days that aggregation filter will take into consideration
days = 3

[Pollutant]
# The text that will appear in the web app page indicating the weighing 
# options. The user can choose between fastest, shortest (which are supported 
# by GH but only fastest is
#implemented in the web app). Given available sensor data, the user can also choose to maximize, minimize sensor data;i.e LeastNoisy for the Noisetube sensor.
text = Least_Pollution

# Type of sensor readings; e.g. noise, air...etc. To be used to in naming the hashes, such as city_type_set. That's important to be able to retrieve the relevant readings  of the
#relevant city from Graphhooper during routing calculation
type = pollutant

# Directory where the sensor parser stores the aggregated data
dirname = sensor_readings/air/
